{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Physician Notetaker - Medical Transcription & NLP Analysis\n",
        "\n",
        "This notebook demonstrates the complete medical transcription analysis system including:\n",
        "1. Medical NLP Summarization (NER, Text Summarization, Keyword Extraction)\n",
        "2. Sentiment & Intent Analysis\n",
        "3. SOAP Note Generation (Bonus)\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root / 'src'))\n",
        "\n",
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Import modules\n",
        "from pipeline import PhysicianNotetakerPipeline\n",
        "\n",
        "print(\"Imports successful!\")\n",
        "print(f\"Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Sample Transcript\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample transcript\n",
        "transcript_path = project_root / 'tests' / 'test_sample_transcript.txt'\n",
        "\n",
        "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "    sample_transcript = f.read()\n",
        "\n",
        "print(\"Sample Transcript:\")\n",
        "print(\"=\" * 60)\n",
        "print(sample_transcript[:500] + \"...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal length: {len(sample_transcript)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the pipeline\n",
        "# API key is read from GEMINI_API_KEY environment variable\n",
        "pipeline = PhysicianNotetakerPipeline()\n",
        "\n",
        "print(\"Pipeline initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Medical NLP Summarization\n",
        "\n",
        "### 1.1 Named Entity Recognition (NER)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from medical_ner import MedicalNER\n",
        "\n",
        "# Initialize NER module\n",
        "ner = MedicalNER(gemini_client=pipeline.client)\n",
        "\n",
        "# Extract medical entities\n",
        "print(\"Extracting medical entities...\")\n",
        "entities = ner.extract_entities(sample_transcript)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MEDICAL ENTITIES EXTRACTED\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(entities, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Keyword Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract important medical keywords\n",
        "print(\"Extracting medical keywords...\")\n",
        "keywords = ner.extract_keywords(sample_transcript, top_n=15)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MEDICAL KEYWORDS\")\n",
        "print(\"=\" * 60)\n",
        "for i, keyword in enumerate(keywords, 1):\n",
        "    print(f\"{i}. {keyword}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Structured Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get complete structured summary\n",
        "print(\"Generating structured medical summary...\")\n",
        "structured_summary = ner.extract_structured_summary(sample_transcript)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STRUCTURED MEDICAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(structured_summary, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Text Summarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from summarization import MedicalSummarizer\n",
        "\n",
        "# Initialize summarizer\n",
        "summarizer = MedicalSummarizer(gemini_client=pipeline.client)\n",
        "\n",
        "# Generate comprehensive summary\n",
        "print(\"Generating medical text summary...\")\n",
        "medical_summary = summarizer.summarize(sample_transcript)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MEDICAL TEXT SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(medical_summary, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sentiment & Intent Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentiment_analysis import SentimentAnalyzer\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "sentiment_analyzer = SentimentAnalyzer(gemini_client=pipeline.client)\n",
        "\n",
        "# Analyze full transcript\n",
        "print(\"Analyzing patient sentiment and intent...\")\n",
        "sentiment_analysis = sentiment_analyzer.analyze_full_transcript(sample_transcript)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SENTIMENT & INTENT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(sentiment_analysis, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Analyzing Individual Patient Statements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example patient statements\n",
        "example_statements = [\n",
        "    \"I'm doing better, but I still have some discomfort now and then.\",\n",
        "    \"That's a relief!\",\n",
        "    \"That's great to hear. So, I don't need to worry about this affecting me in the future?\"\n",
        "]\n",
        "\n",
        "print(\"Analyzing individual patient statements:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, statement in enumerate(example_statements, 1):\n",
        "    result = sentiment_analyzer.analyze_sentiment(statement)\n",
        "    print(f\"\\nStatement {i}: {statement}\")\n",
        "    print(f\"  Sentiment: {result['Sentiment']}\")\n",
        "    print(f\"  Intent: {result['Intent']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SOAP Note Generation (Bonus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from soap_generator import SOAPGenerator\n",
        "\n",
        "# Initialize SOAP generator\n",
        "soap_generator = SOAPGenerator(gemini_client=pipeline.client)\n",
        "\n",
        "# Generate SOAP note\n",
        "print(\"Generating SOAP note...\")\n",
        "soap_note = soap_generator.generate_soap_note(sample_transcript)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SOAP NOTE (JSON Format)\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(soap_note, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SOAP Note in Text Format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display SOAP note in readable text format\n",
        "soap_text = soap_generator.format_soap_note(soap_note, format_type=\"text\")\n",
        "print(soap_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Pipeline Processing\n",
        "\n",
        "Process the entire transcript through all modules at once:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process complete transcript\n",
        "print(\"Processing complete transcript through pipeline...\")\n",
        "print(\"This may take a few moments...\\n\")\n",
        "\n",
        "results = pipeline.process_transcript(sample_transcript, include_soap=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPLETE ANALYSIS RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(json.dumps(results, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export Results in Text Format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results in human-readable text format\n",
        "text_output = pipeline.export_results(results, format_type=\"text\")\n",
        "print(text_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Medical NER extraction (Symptoms, Diagnosis, Treatment, Prognosis)\n",
        "- Text summarization with structured output\n",
        "- Keyword extraction from medical transcripts\n",
        "- Sentiment analysis (Anxious/Neutral/Reassured)\n",
        "- Intent detection (Seeking reassurance, Reporting symptoms, etc.)\n",
        "- SOAP note generation (Subjective, Objective, Assessment, Plan)\n",
        "\n",
        "All modules use Google's Gemini 2.5 Flash API for accurate medical NLP processing.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
